{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*UE Learning from User-generated Data, CP MMS, JKU Linz 2022*\n",
    "# Exercise 3: Model-based approaches\n",
    "In this exercise we'll have a look at two different takes on Matrix Factorization and prepare to learn about ways to evaluate recommender systems.\n",
    "\n",
    "The assignment submission deadline is 26.04.2022 23:59.\n",
    "\n",
    "Make sure to rename the notebook according to the convention:\\\n",
    "LUD22_ex03_k<font color='red'>\\<Matr. Number\\></font>_<font color='red'>\\<Surname-Name\\></font>.ipynb\n",
    "\n",
    "for example:\n",
    "\n",
    "LUD22_ex03_k000007_Bond-James.ipynb\n",
    "\n",
    "## Implementation\n",
    "In this exercise, as before, you are reqired to write a number of functions. Insert your implementations into the templates provided. Please don't change the templates even if they are not pretty. Don't forget to test your implementation for correctness and efficiency.\n",
    "\n",
    "Please **only use libraries already imported in the notebook**. *Feel free to experiment with the notebook, but clean it up before submitting.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# data reader from previous exercises\n",
    "def inter_matr_binary(usr_path='sampled_1000_items_demo.txt',\n",
    "                      itm_path='sampled_1000_items_tracks.txt',\n",
    "                      inter_path='sampled_1000_items_inter.txt',\n",
    "                      threshold=1) -> np.ndarray:\n",
    "    '''\n",
    "    usr_path - string path to the file with users data;\n",
    "    itm_path - string path to the file with item data;\n",
    "    inter_path - string path to the file with interaction data;\n",
    "    threshold - int > 0, criteria of a valid interaction\n",
    "    \n",
    "    returns - 2D np.array, rows - users, columns - items;\n",
    "    '''\n",
    "\n",
    "    res = None\n",
    "\n",
    "    # reading the three data files\n",
    "    users = pd.read_csv(usr_path, sep='\\t', header=None, names=['location', 'age', 'gender', 'date'])\n",
    "    items = pd.read_csv(itm_path, sep='\\t', header=None, names=['artist', 'track'])\n",
    "    interactions = pd.read_csv(inter_path, sep='\\t', header=None, names=['user', 'item', 'num_inters'])\n",
    "\n",
    "    # getting number of users and items from the respective files to be on the safe side\n",
    "    n_users = len(users.index)\n",
    "    n_items = len(items.index)\n",
    "\n",
    "    # preparing the output matrix\n",
    "    res = np.zeros([n_users, n_items])\n",
    "\n",
    "    # for every interaction assign 1 to the respective element of the matrix\n",
    "    for _, inter in interactions.iterrows():\n",
    "        curr_user = inter['user']\n",
    "        curr_item = inter['item']\n",
    "        res[curr_user, curr_item] = 1 if inter['num_inters'] >= threshold else 0\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization\n",
    "In the previous exercise we implented ItemKNN which is a Memory-based approach. It means that in order for the model to function we have to keep all known to us interactions (the full interaction matrix) in the memory, this can be cumbersome.\n",
    "    \n",
    "The idea of Model-based approaches is to learn some kind of compact representation of the matrix. Most common scenario is the following: instead of representing every user through all the items and every item through all the users (full interaction matrix) let's represent both in a latent vector space of some smaller dimensionality **f**.\n",
    "\n",
    "It means that instead of the one full interaction matrix **inter**: (**users** x **items**) we'll need to keep in memory two much smaller matrices: one with user-representations **U**: (**users** x **f**), one with item representations **V**: (**items** x **f**). And we'll learn those two in such a way that we can recreate the information contained in the full interaction matrix, for example through dot product:\n",
    "    \n",
    "inter[**user**, **item**] = U[**user**, :] @ V[**item**, :].T\n",
    "    \n",
    "Such approach is generally called Matrix Factorization, because we split one huge unbearable matrix into multiple smaller bearable ones. It has the following benefits:\n",
    "* The two new matrices combined (should) take less space than the full interaction matrix and thus easier fit into memory;\n",
    "* Selecting a reasonable **f** means that we operate with shorter vectors during all kinds of calculations, this decreases computational load during recommendation making online inference easier;\n",
    "* Matrix factorization compresses sparce information contained in the interaction matrix into an elegant representation and can potentially encode **hidden dependencies**;\n",
    "* Having both items and users represented in the the same **f**-dimensional space opens new possibilities for recommendation;\n",
    "    \n",
    "Now let's have a look at how we can actually perform this trick.\n",
    "    \n",
    "### Singular Value Decomposition (SVD)\n",
    "As it often happens, linear algebra has answers. And Singular Vector Decomposition is one.\n",
    "\n",
    "A $n * m$ matrix $I$ can be decomposed into a product of 3 matrices:<br>\n",
    "$I = U\\Sigma V^T$\n",
    "\n",
    "$U$ -- orthogonal ($n * n$) matrix composed of left singular vectors (it corresponds to users);<br>\n",
    "$\\Sigma$ -- ($n * m$) diagonal matrix, containing singular values;<br>\n",
    "$V$ -- orthogonal ($m * m$) matrix composed of right singular vectors (it corresponds to items);<br>\n",
    "\n",
    "#### <font color='#666666'>Thin Variant</font> of  Singular Vector Decomposition\n",
    "As before:<br>\n",
    "$I = U\\Sigma V^T$\n",
    "\n",
    "We can exploit the fact that $I$ (usually) is not square and cannot have *full rank*.<br>\n",
    "$k = min(n, m)$\n",
    "\n",
    "As a result $U$, $\\Sigma$ and $V$ have different dimensions:<br>\n",
    "$U$ -- ($n *$ <font color='red'>$k$</font>) of left singular vectors (it corresponds to users);<br>\n",
    "$\\Sigma$ -- (<font color='red'>$k$</font> $*$ <font color='red'>$k$</font>) square diagonal matrix, containing singular values;<br>\n",
    "$V$ -- ($m *$ <font color='red'>$k$</font>) of right singular vectors (it corresponds to items);<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users' representations:\n",
      " [[ 5.42463675e-01 -9.81751217e-02  7.07106781e-01 -4.42825933e-01]\n",
      " [ 5.97192605e-01  5.10969410e-01  1.60982339e-15  6.18280887e-01]\n",
      " [ 2.34152336e-01 -8.48312179e-01 -2.38697950e-15  4.74909602e-01]\n",
      " [ 5.42463675e-01 -9.81751217e-02 -7.07106781e-01 -4.42825933e-01]] \n",
      "\n",
      "items' representations:\n",
      " [[ 4.42491536e-01  2.76337063e-01 -5.00000000e-01  4.77324909e-01]\n",
      " [ 3.01534785e-01 -6.33607412e-01  5.00000000e-01  8.72835678e-02]\n",
      " [ 4.42491536e-01  2.76337063e-01  5.00000000e-01  4.77324909e-01]\n",
      " [ 6.53112570e-01  2.10615648e-01  7.00828284e-16 -7.27382307e-01]\n",
      " [ 3.01534785e-01 -6.33607412e-01 -5.00000000e-01  8.72835678e-02]] \n",
      "\n",
      "singular values: [2.57554368 1.49380718 1.41421356 0.36757971] \n",
      "\n",
      "reconstructed matrix\n",
      " [[ 2.18105159e-16  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   2.90442620e-16]\n",
      " [ 1.00000000e+00  4.30508487e-16  1.00000000e+00  1.00000000e+00\n",
      "   3.31469520e-16]\n",
      " [ 3.39422927e-16  1.00000000e+00  6.14107010e-16  1.51460008e-16\n",
      "   1.00000000e+00]\n",
      " [ 1.00000000e+00 -9.03962509e-17  2.37473259e-16  1.00000000e+00\n",
      "   1.00000000e+00]] \n",
      "\n",
      "reconstructed matrix (rounded)\n",
      " [[ 0.  1.  1.  1.  0.]\n",
      " [ 1.  0.  1.  1.  0.]\n",
      " [ 0.  1.  0.  0.  1.]\n",
      " [ 1. -0.  0.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# consider an interaction matrix with 4 users and 5 items\n",
    "inter_matr = np.array(\n",
    "    [\n",
    "        [0, 1, 1, 1, 0],\n",
    "        [1, 0, 1, 1, 0],\n",
    "        [0, 1, 0, 0, 1],\n",
    "        [1, 0, 0, 1, 1]\n",
    "    ]\n",
    ")\n",
    "# let's now apply Thin (k==4) SVD to it, we'll get the following: \n",
    "\n",
    "# U - (4, 4) matrix, corresponding to users\n",
    "# s - (4) singular values - each element shows how informative the corresponding dimension is\n",
    "# Vh - (4, 5) already transposed matrix corresponding to items\n",
    "\n",
    "# we set 'full_matrices' to 'False' for Thin SVD\n",
    "U, s, Vh = np.linalg.svd(inter_matr, full_matrices=False)\n",
    "\n",
    "# let's quickly construct the matrix back to make sure everything works\n",
    "res = (U @ np.diag(s)) @ Vh\n",
    "\n",
    "print('users\\' representations:\\n', U, '\\n')\n",
    "print('items\\' representations:\\n', Vh.T, '\\n')  # Transposing to have first dimension correspond to items\n",
    "print('singular values:', s, '\\n')\n",
    "print('reconstructed matrix\\n', res, '\\n')\n",
    "print('reconstructed matrix (rounded)\\n', res.round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cool things about SVD\n",
    "SVD projects all the variance contained in the data onto orthogonal basis of $k$ vectors.<br>\n",
    "Singular values ($\\Sigma$ or $s$) allow us to judge how much variance is \"situated\" along each vector. It is also acts as weighting for the $k$ dimensions;\n",
    "\n",
    "| $\\Sigma$ |  |  |  |\n",
    "|--|--|--|--|\n",
    "| **2.58** | 0.0 | 0.0 | 0.0 |\n",
    "| 0.0 | **1.49** | 0.0  | 0.0 |\n",
    "| 0.0 | 0.0 | **1.41** | 0.0 |\n",
    "| 0.0 | 0.0 | 0.0 | **0.37** |\n",
    "\n",
    "Basing on that, we can choose $f < k$ (remember $f$?â¬†) dimensions to represent the whole data. Choosing dimensions corresponding to lagest singular values we make sure to keep most of the information contained in the full interaction matrix while decreasing its size and maybe even filtering some noise out. $U$ and $V^T$ become ($n *$ <font color='red'>$f$</font>) and (<font color='red'>$f$</font> $* m$) respectively.<br><br>\n",
    "Let's select only $f = 2$ or $3$ **first** latent features out of $4$ we got, and check how the matrix will change. This is called **truncated SVD**.\n",
    "\n",
    "**Note!** We take first $f$ latent features, because they correspond to higher variance (usually SVD implementations arrange the dimensions in the order of decreasing variance). Higer variance means more *signal* captured with the corresponding dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstructed interaction matrix with f = 4, no truncation:\n",
      " [[ 0.  1.  1.  1.  0.]\n",
      " [ 1.  0.  1.  1.  0.]\n",
      " [ 0.  1.  0.  0.  1.]\n",
      " [ 1. -0.  0.  1.  1.]]\n",
      "reconstructed interaction matrix with f =  3 , truncated:\n",
      " [[ 0.  1.  1.  1.  0.]\n",
      " [ 1. -0.  1.  1. -0.]\n",
      " [-0.  1. -0.  0.  1.]\n",
      " [ 1.  0.  0.  1.  1.]]\n",
      "reconstructed interaction matrix with f =  2 , truncated:\n",
      " [[ 1.  1.  1.  1.  1.]\n",
      " [ 1. -0.  1.  1. -0.]\n",
      " [-0.  1. -0.  0.  1.]\n",
      " [ 1.  1.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print('reconstructed interaction matrix with f = 4, no truncation:\\n', res.round())\n",
    "\n",
    "# Taking 3 most informative dimensions\n",
    "f = 3\n",
    "res_trunc_3 = (U[:, :f] @ np.diag(s[:f])) @ Vh[:f, :]\n",
    "print('reconstructed interaction matrix with f = ', f, ', truncated:\\n', res_trunc_3.round())\n",
    "\n",
    "# Taking only 2 most informative dimensions\n",
    "f = 2\n",
    "res_trunc_2 = (U[:, :f] @ np.diag(s[:f])) @ Vh[:f, :]\n",
    "print('reconstructed interaction matrix with f = ', f, ', truncated:\\n', res_trunc_2.round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can notice that selecting 3 most informative features gives a result very similar to the full set of features. This is no wonder, the 4th dimension corresponds to the lowest variance of 0.37, see the table above.\n",
    "\n",
    "Selecting 2 most informative features gives visible difference in the result even within our toy example.\n",
    "\n",
    "#### Final representations\n",
    "Our goal with matrix factorization is to have two matrices: one for users and the other for items. Right now we have an array of weights (singular values) in addition to this. For the sake of convenience let's just merge those weights into the two matrices (see lecture slides):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction Matrix reconstructed through U, V and s:\n",
      " [[ 0.  1.  1.  1.  0.]\n",
      " [ 1.  0.  1.  1.  0.]\n",
      " [ 0.  1.  0.  0.  1.]\n",
      " [ 1. -0.  0.  1.  1.]] \n",
      "\n",
      "Interaction Matrix reconstructed through U_final and V_final:\n",
      " [[ 0.  1.  1.  1.  0.]\n",
      " [ 1.  0.  1.  1.  0.]\n",
      " [ 0.  1.  0.  0.  1.]\n",
      " [ 1. -0.  0.  1.  1.]] \n",
      "\n",
      "Original Interaction Matrix:\n",
      " [[0 1 1 1 0]\n",
      " [1 0 1 1 0]\n",
      " [0 1 0 0 1]\n",
      " [1 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "U_final = U @ np.diag(s ** 0.5)  # users x features\n",
    "V_final = (np.diag(s ** 0.5) @ Vh).T  # items x features\n",
    "\n",
    "print('Interaction Matrix reconstructed through U, V and s:\\n', ((U @ np.diag(s)) @ Vh).round(), '\\n')\n",
    "print('Interaction Matrix reconstructed through U_final and V_final:\\n', (U_final @ V_final.T).round(), '\\n')\n",
    "print('Original Interaction Matrix:\\n', inter_matr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in the two final matrices of representations U_final and V_final we essentially have user- and item-embeddings stored. All what is left is to truncate them to our liking (select $f$ first dimensions) and proceed to recommendation.\n",
    "\n",
    "Reasons to truncate:\n",
    "* Save space in memory\n",
    "* Dimensions with lower corresponding variance are likely to contain noise. Truncating the representations we concentrate on the strongest patterns\n",
    "\n",
    "#### Recommendation with Matrix Factorization\n",
    "With the two sets of embeddings U_final and V_final there is a multitude of ways to recommend items to users.\n",
    "In this exercise we take advantage of the fact that we represent both users and items in the same f-dimensional vector space. It means that we can estimate similarity directly between users and items, using, for example, cosine similarity.\n",
    "\n",
    "So to recommend items for a user with id **u** we would create a list of all items ranked according to the cosine similarity between the user vector U_final[**u**,:] and corresponding item-vectors from V_final (V_final[**i**, :], make sure to take the correct orientation of the matrix). Then as before we should remove items already seen by the user and take Top K (how ever many recommendations we need) of the resulting list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>TASK 1/3</font>: Matrix Factorization with SVD\n",
    "Complete the templates below to create an MF-SVD recommender.\\\n",
    "The first function should return two sets of embeddings (for users and for items) of given length (Truncated SVD!).\n",
    "\n",
    "Make sure to put the data files: *sampled_1000_items_inter.txt*, *sampled_1000_items_demo.txt* and *sampled_1000_items_tracks.txt* next to the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_decompose(inter_matr: np.ndarray, f=50) -> (np.ndarray, np.ndarray):\n",
    "    \"\"\"\n",
    "    inter_matr - np.ndarray - interaction matrix to construct svd from.\n",
    "    f - int - expected size of embeddings\n",
    "    \n",
    "    returns - U_final, V_final - (as above) user-/item-embeddings of given length f\n",
    "    \"\"\"\n",
    "\n",
    "    U_final = None\n",
    "    V_final = None\n",
    "\n",
    "    # TODO: YOUR IMPLEMENATION.\n",
    "    U, s, Vh = np.linalg.svd(inter_matr, full_matrices=False)\n",
    "\n",
    "    U_final = U[:, :f] @ np.diag(s[:f] ** 0.5)  # users x features\n",
    "    V_final = (np.diag(s[:f] ** 0.5) @ Vh[:f, :]).T  # items x features\n",
    "\n",
    "    return U_final, V_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_inter = inter_matr_binary(usr_path='sampled_1000_items_demo.txt',\n",
    "                                     itm_path='sampled_1000_items_tracks.txt',\n",
    "                                     inter_path='sampled_1000_items_inter.txt')\n",
    "\n",
    "U, V = svd_decompose(train_data_inter, 60)\n",
    "\n",
    "assert U is not None and V is not None, \"The variables should not be None.\"\n",
    "assert U.shape == (1194, 60), \"U has incorrect shape\"\n",
    "assert V.shape == (412, 60), \"V has incorrect shape\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is meant for Batch recommendation. Given a list of User ids, a list of arrays with item ids consumed by the respective users, U_final, V_final and expected number of recommendations, the function returns a list of recommendation arrays for every user. The order of users should correspond to the order in the input list, the items, as before, should be ordered from most to least recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_recommend_to_list(user_ids: list, seen_item_ids: list, U: np.ndarray, V: np.ndarray, topK: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Recommend with svd to selected users\n",
    "    \n",
    "    user_ids - list[int] - ids of target users.\n",
    "    seen_item_ids - list[list[int]] ids of items already seen by the users (to exclude from recommendation)\n",
    "    U and V - user- and item-embeddings\n",
    "    topK - number of recommendations per user to be returned\n",
    "    \n",
    "    returns - np.ndarray - list of lists of ids of recommended items in the order of descending score, for every user\n",
    "                           make sure the dimensions are correct: [(number of user_ids) x (topK)]\n",
    "                           use -1 as a place holder item index, when it is impossible to recommend topK items\n",
    "    \"\"\"\n",
    "    recs = None\n",
    "\n",
    "    # TODO: YOUR IMPLEMENTATION.\n",
    "\n",
    "    if topK > 412:\n",
    "        raise ValueError\n",
    "\n",
    "    recs = np.full(shape=(len(user_ids), topK), fill_value=-1)\n",
    "\n",
    "    my_matrix = cosine_similarity(U[user_ids, :], V)\n",
    "    for i, user in enumerate(user_ids):\n",
    "        my_matrix[i, seen_item_ids[i]] = -np.inf\n",
    "\n",
    "        score_ind = np.argsort(my_matrix[i])\n",
    "        # indices, sorted in the order of descending popularity\n",
    "\n",
    "        recs[i] = score_ind[-topK:][::-1]\n",
    "\n",
    "        ##Didn't optimize and test yet, might not work optimally\n",
    "        maxvalue = (topK + len(seen_item_ids[i])) - 411\n",
    "        if maxvalue > 0:\n",
    "            for k in range(maxvalue):\n",
    "                recs[i, -k] = -1\n",
    "\n",
    "    return np.asarray(recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>TASK 2/3</font>: Iterative Matrix Factorization with PyTorch\n",
    "\n",
    "In the first task we utilized a deterministic method (SVD) to obtain user- and item-embeddings. It means that an equation needs to be solved every time we do so, and the whole process (for the whole matrix) needs to be repeated every time a new item or a new user are added to the system. Notice also that with SVD we are doing some extra work by first getting the embbeddings of length k and then truncating them to our desired length.\n",
    "\n",
    "Iterative approach to MF allows us to train embeddings of the desired length straight away, gives more flexibility in setting the training objective and updating the parameters/adding new users (e.g. through 'fine tuning').\n",
    "\n",
    "Your task is to implemet matrix factorization using PyTorch, please follow the specifciactions closely and referer to the provided introduction to PyTorch (separate notebook). Use Moodle forum if you have any questions.\n",
    "\n",
    "First, you need to construct a module consisting of two layers (those will be our **U_final** and **V_final** that we are after):\n",
    "\n",
    "1) An Embedding Layer from User space to Latent space  (user id -> f-dim vector)<br>\n",
    "2) An Embedding Layer from Item space to Latent space (item id -> f-dim vector)<br>\n",
    "\n",
    "Use the <b>nn.Embedding</b> Module. Implement the forward function: as with SVD we'll set the training objective to reconstruct the interaction matrix. So multiplying U and V (with transposition applied correctly) we should get an approximation of the interaction matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "\n",
    "    def __init__(self, n_users: int, n_items: int, n_factors: int):\n",
    "        \"\"\"\n",
    "        n_users - int - number of users.\n",
    "        n_items - int - number of items.\n",
    "        n_factors - int - dimensionality of the latent space.\n",
    "        \"\"\"\n",
    "\n",
    "        super(MF, self).__init__()\n",
    "\n",
    "        self.embedding_user = None\n",
    "        self.embedding_item = None\n",
    "\n",
    "        # TODO: YOUR IMPLEMENTATION.\n",
    "\n",
    "        self.embedding_user = nn.Embedding(n_users, n_factors)\n",
    "        self.embedding_item = nn.Embedding(n_items, n_factors)\n",
    "\n",
    "        # to initialize the weight of some layer with a constant value.\n",
    "        #nn.init.constant_(self.embedding_user.weight, 0.8)\n",
    "        #nn.init.constant_(self.embedding_item.weight, 0.3)\n",
    "\n",
    "    def forward(self, user: torch.Tensor, item: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        We allow for some flexibility giving lists of ids as inputs:\n",
    "        if the training data is small we can deal with it in a single forward pass,\n",
    "        otherwise we could fall back to mini-batches, limiting users and items we pass\n",
    "        every time.\n",
    "\n",
    "        user - torch.Tensor - user_ids.\n",
    "        item - torch.Tensor - item_ids.\n",
    "\n",
    "        returns - torch.Tensor - Reconstructed Interaction matrix of shape (n_users, n_items).\n",
    "        \"\"\"\n",
    "        res = None\n",
    "\n",
    "        # TODO: YOUR IMPLEMENTATION.\n",
    "        user = self.embedding_user(user)\n",
    "        item = self.embedding_item(item)\n",
    "\n",
    "        return torch.matmul(user, item.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a model with the two embedding sets, and it is able to reconstruct the interaction matrix through them.\n",
    "\n",
    "Next we need a way to evaluate the reconstruction effort, this is what loss function helps us with.\n",
    "For our case we will use the Binary Cross Entropy Loss, please implement the compute_loss function and use nn.BCELoss to calculate the loss.\n",
    "\n",
    "<b>Tip:</b> Make sure to first project the logits to the [0, 1] interval using sigmoid activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def compute_loss(logits: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    logits - torch.Tensor - output of model.\n",
    "    labels - torch.Tensor - labels / interaction matrix model should learn to reconstruct.\n",
    "\n",
    "    returns - torch.Tensor - BCELoss over all logits and labels.\n",
    "    \"\"\"\n",
    "    loss = None\n",
    "\n",
    "    # TODO: YOUR IMPLEMENTATION.\n",
    "    logits = torch.sigmoid(logits)\n",
    "\n",
    "    loss = nn.BCELoss()\n",
    "    return loss(logits, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the train function and return the loss over all epochs.\n",
    "For simplicity we pass the full interaction matrix (all user and item ids) at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, train_data_inter: np.ndarray, epochs: int, optimizer, loss_func) -> list:\n",
    "    \"\"\"\n",
    "    model - nn.Module - torch module to train.\n",
    "    train_data_inter - np.ndarray - interaction matrix of the training data.\n",
    "    epochs - int - number of epochs to perform.\n",
    "    optimizer - optim - optimizer for training.\n",
    "    loss_func - loss function for training.\n",
    "    \n",
    "    returns - list - list of loss values over all epochs.\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "\n",
    "    model.train()\n",
    "    # TODO: YOUR IMPLEMENTAION.\n",
    "\n",
    "    user_ids = torch.IntTensor(list(range(train_data_inter.shape[0])))\n",
    "    item_ids = torch.IntTensor(list(range(train_data_inter.shape[1])))\n",
    "\n",
    "    train_data_inter = torch.Tensor(train_data_inter)\n",
    "    for _ in range(epochs):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(user_ids, item_ids)\n",
    "        loss = loss_func(prediction, train_data_inter)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if _ % 10 == 0:\n",
    "            print(loss.item())\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model with the following parameters\n",
    "\n",
    "<b>Learning rate:</b> 0.001<br>\n",
    "<b>Optimizer:</b> Adam<br>\n",
    "<b>Factor size:</b> 128<br>\n",
    "\n",
    "Of course, we encourage you to try out multiple different paremeters, just for you to get a feeling of this model, but for this exercise we fixed the parameters for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do not change the seed.\n",
    "torch.manual_seed(1234)\n",
    "rnd.seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "model_128 = None\n",
    "optimizer = None\n",
    "\n",
    "# TODO: YOUR IMPLEMENATION.\n",
    "# Initialize the model and optimizer as prescribed\n",
    "#1194 users, 412 songs\n",
    "model_128 = MF(1194, 412, n_factors=128)\n",
    "\n",
    "optimizer = optim.Adam(model_128.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model_128 is not None and optimizer is not None, \"Model and optimizer should be initilized.\"\n",
    "assert type(optimizer) == optim.Adam\n",
    "\n",
    "assert model_128.embedding_user is not None and model_128.embedding_item is not None, \"Embedding Layers need to be not None.\"\n",
    "assert type(model_128.embedding_user) == nn.Embedding, \"Embedding Layer should be of type nn.Embedding.\"\n",
    "assert type(model_128.embedding_item) == nn.Embedding, \"Embedding Layer should be of type nn.Embedding.\"\n",
    "\n",
    "assert model_128.embedding_item.embedding_dim == 128, \"Item Embedding Layer wrong embedding size.\"\n",
    "assert model_128.embedding_user.embedding_dim == 128, \"User Embedding Layer wromg embedding size.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training model\n",
    "\n",
    "Lets train the model for <b>1000</b> epochs and look at the returned loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.99675464630127\n",
      "9.740233421325684\n",
      "9.49190902709961\n",
      "9.242265701293945\n",
      "8.9867582321167\n",
      "8.740788459777832\n",
      "8.48522663116455\n",
      "8.217864990234375\n",
      "7.948935031890869\n",
      "7.657566070556641\n",
      "7.372904300689697\n",
      "7.056423187255859\n",
      "6.728239059448242\n",
      "6.395613670349121\n",
      "6.0357489585876465\n",
      "5.64617395401001\n",
      "5.258042812347412\n",
      "4.865944862365723\n",
      "4.476346969604492\n",
      "4.09126615524292\n",
      "3.7147958278656006\n",
      "3.3527164459228516\n",
      "3.003810167312622\n",
      "2.6759297847747803\n",
      "2.379127025604248\n",
      "2.122225761413574\n",
      "1.8778239488601685\n",
      "1.6669727563858032\n",
      "1.4816986322402954\n",
      "1.3161985874176025\n",
      "1.17442786693573\n",
      "1.055530309677124\n",
      "0.9546449184417725\n",
      "0.862669050693512\n",
      "0.7839226722717285\n",
      "0.7139539122581482\n",
      "0.652629554271698\n",
      "0.6042264699935913\n",
      "0.5617193579673767\n",
      "0.5234028100967407\n",
      "0.4913998544216156\n",
      "0.46379512548446655\n",
      "0.4393714368343353\n",
      "0.41683274507522583\n",
      "0.3945385217666626\n",
      "0.37724289298057556\n",
      "0.3611605763435364\n",
      "0.34647074341773987\n",
      "0.3333786725997925\n",
      "0.3214273154735565\n",
      "0.31103450059890747\n",
      "0.3007390797138214\n",
      "0.2916604280471802\n",
      "0.2835707664489746\n",
      "0.2755461633205414\n",
      "0.2684047818183899\n",
      "0.26193487644195557\n",
      "0.2559238076210022\n",
      "0.2500096559524536\n",
      "0.2446681708097458\n",
      "0.23834188282489777\n",
      "0.2337494194507599\n",
      "0.22880996763706207\n",
      "0.22403503954410553\n",
      "0.21956752240657806\n",
      "0.21489080786705017\n",
      "0.2110176384449005\n",
      "0.2070816457271576\n",
      "0.20308300852775574\n",
      "0.19917917251586914\n",
      "0.195704385638237\n",
      "0.19231265783309937\n",
      "0.18865978717803955\n",
      "0.18541939556598663\n",
      "0.1819068193435669\n",
      "0.17880336940288544\n",
      "0.1757618933916092\n",
      "0.17243531346321106\n",
      "0.169338196516037\n",
      "0.1657811850309372\n",
      "0.16296212375164032\n",
      "0.16002056002616882\n",
      "0.15730029344558716\n",
      "0.15462319552898407\n",
      "0.1519947350025177\n",
      "0.14923925697803497\n",
      "0.14669500291347504\n",
      "0.14402657747268677\n",
      "0.14156630635261536\n",
      "0.13897782564163208\n",
      "0.13642720878124237\n",
      "0.13374413549900055\n",
      "0.13126806914806366\n",
      "0.12900258600711823\n",
      "0.12659721076488495\n",
      "0.12422850728034973\n",
      "0.12206680327653885\n",
      "0.11993538588285446\n",
      "0.11766993254423141\n",
      "0.11560531705617905\n"
     ]
    }
   ],
   "source": [
    "loss_model_128 = train(model=model_128,\n",
    "                       train_data_inter=train_data_inter,\n",
    "                       epochs=1000,\n",
    "                       optimizer=optimizer,\n",
    "                       loss_func=compute_loss)\n",
    "\n",
    "assert len(loss_model_128) == 1000, \"Loss should have 1000 elements, one for each epoch.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_model_128, label=\"128\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"BCE Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendations with the trained Factorization Model\n",
    "Write a function that recommends topK items to each of the users, whose ids are given, using the trained model.\n",
    "Recommendation should be done in a fashion similar to *svd_recommend_to_list*: for each user score items based on cosine similarity of the corresponding embeddings. Do not consider items already seen by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def itMF_recommend_to_list(user_ids: list, seen_item_ids: list, model=model_128, topK=10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Recommend with the trained model to selected users\n",
    "    \n",
    "    user_ids - list[int] - ids of target users.\n",
    "    seen_item_ids - list[list[int]] ids of items already seen by the users (to exclude from recommendation)\n",
    "    model - trained factorization model to use for scoring\n",
    "    topK - number of recommendations per user to be returned\n",
    "    \n",
    "    returns - np.ndarray - list of lists of ids of recommended items in the order of descending score, for every user\n",
    "                           make sure the dimensions are correct: [(number of user_ids) x (topK)]\n",
    "                           use -1 as a place holder item index, when it is impossible to recommend topK items\n",
    "    \"\"\"\n",
    "    recs = None\n",
    "\n",
    "    # TODO: YOUR IMPLEMENTATION.\n",
    "\n",
    "    if topK > 412:\n",
    "        raise ValueError\n",
    "\n",
    "    recs = np.full(shape=(len(user_ids), topK), fill_value=-1)\n",
    "\n",
    "    item_ids = torch.IntTensor(list(range(412)))\n",
    "\n",
    "    U = model_128.embedding_user(torch.IntTensor(user_ids)).detach().numpy()\n",
    "    V = model_128.embedding_item(item_ids).detach().numpy()\n",
    "\n",
    "    my_matrix = cosine_similarity(U, V)\n",
    "\n",
    "    for i, user in enumerate(user_ids):\n",
    "        my_matrix[i, seen_item_ids[i]] = -np.inf\n",
    "\n",
    "        score_ind = np.argsort(my_matrix[i])\n",
    "        recs[i] = score_ind[-topK:][::-1]\n",
    "\n",
    "    return np.asarray(recs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#inter_act_matr = inter_matr_binary()\n",
    "#users_list = [0, 1, 2, 3, 4, 5, 6]\n",
    "#seen_list = [np.where(inter_act_matr[user] != 0)[0] for user in users_list]\n",
    "\n",
    "#recs = svd_recommend_to_list(users_list, seen_list, U, V, 10)\n",
    "#print(recs)\n",
    "\n",
    "#recs = itMF_recommend_to_list(users_list, seen_list, MF)\n",
    "#print(recs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>TASK 3/3</font>: Data Split\n",
    "In order to minimize influence of random chance during evaluation it is good to conduct it on multiple different Data Splits.\n",
    "In this task you are required to write a function that randomly splits all the interactions into TEST and TRAIN files in given proportion (0.2 by default, meaning 20% of interactions should become the TEST set).\n",
    "\n",
    "It should receive a name of a file, containing interaction data in LFM2B format (as in the previous exercise) as input.The function is expected to randomly split the records from the file, approximately in given proportion into Train and Test sets (proportion of 0.2 means that the number of Test records to the number of Train records should be 20:80).The function needs to save the result into two separate files in LFM2B format, one for Test interactions, one for Train interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_interactions(inter_file='sampled_1000_items_inter.txt',\n",
    "                       proportion=0.2,\n",
    "                       res_test_file='sampled_1000_items_inter_TEST.txt',\n",
    "                       res_train_file='sampled_1000_items_inter_TRAIN.txt'):\n",
    "    '''\n",
    "    inter_file - string - path to the file with interaction data in LFM2B format;\n",
    "    proportion - float - proportion of records from inter_file to become the Test Set;\n",
    "    res_test_file - string - Test records will be saved here;\n",
    "    res_train_file - string - Train records will be saved here;\n",
    "    \n",
    "    returns - nothing, but saves the two files in LF2B format;\n",
    "    '''\n",
    "\n",
    "    interactions = pd.read_csv(inter_file, sep='\\t', header=None, names=['user', 'item', 'num_inters'])\n",
    "\n",
    "    train = None\n",
    "    test = None\n",
    "\n",
    "    # TODO: YOUR IMPLEMENTATION.\n",
    "    interactions = interactions.sample(frac=1).reset_index(drop=True)\n",
    "    split = int(interactions.shape[0] * (1 - proportion))\n",
    "    train = interactions[:split]\n",
    "    test= interactions[split:]\n",
    "\n",
    "    # saving the res files\n",
    "    # train and test - pd.DataFrames\n",
    "    train.to_csv(res_train_file, index=False, header=False, sep='\\t')\n",
    "    test.to_csv(res_test_file, index=False, header=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_interactions(inter_file='sampled_1000_items_inter.txt',\n",
    "                   proportion=0.2,\n",
    "                   res_test_file='sampled_1000_items_inter_TEST.txt',\n",
    "                   res_train_file='sampled_1000_items_inter_TRAIN.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test interactions, you just split up.\n",
    "\n",
    "train_data_inter = None\n",
    "test_data_inter = None\n",
    "\n",
    "train_data_inter = inter_matr_binary(usr_path='sampled_1000_items_demo.txt',\n",
    "                                     itm_path='sampled_1000_items_tracks.txt',\n",
    "                                     inter_path='sampled_1000_items_inter_TRAIN.txt')\n",
    "test_data_inter = inter_matr_binary(usr_path='sampled_1000_items_demo.txt',\n",
    "                                    itm_path='sampled_1000_items_tracks.txt',\n",
    "                                    inter_path='sampled_1000_items_inter_TEST.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len = len(test_data_inter[test_data_inter == 1])\n",
    "train_len = len(train_data_inter[train_data_inter == 1])\n",
    "prop = test_len / (train_len + test_len)\n",
    "# very rough evaluation\n",
    "assert prop < 0.3, \"Test set is too big.\"\n",
    "assert prop > 0.1, \"Test set is too small.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The end."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}